## 5.3 다중 스레드 성능 방해자
- CPU가 4바이트 정수에 접근해야 하는데 캐시가 적중하지 않는다면?
### 5.3.1 캐시와 메모리 상호 작용의 기본 단위: 캐시 라인
- 자주 사용되는 데이터와 가까이 있는 데이터도 자주 참조될 가능성이 높다
- 그러므로 캐시 대상 데이터의 근처에 있는 데이터까지 캐시로 저장하는 것이 합리적이다(공간적 지역성)
- 캐시로 저장해야할 데이터 덩어리들을 캐시 라인이라고 한다
- 보통 64바이트이다
- 캐시가 적중하지 못하면 캐시 라인이 캐시에 저장된다
### 5.3.2 첫 번째 성능 방해자: 캐시 튕김 문제
- 동시성 처리를 위해 atomic 으로 선언한 전역 변수를 연산하는 두 개의 프로그램이 있다
	- 하나는 단일 스레드
	- 하나는 다중 스레드
- 당연히 단일 스레드의 처리 속도가 훨씬 빠르다
- 다중 스레드 환경에서는 연산을 할 때 마다 다른 캐시에 적재된 데이터를 무효화 해야 한다
	- 각 스레드가 서로 다른 스레드가 참조하는 캐시를 무효화하는 것이 마치 핑퐁처럼 이어진다
	- 이것이 캐시 튕김 혹은 캐시 핑퐁이라는 문제라고 한다
### 5.3.3 두 번째 성능 방해자: 거짓 공유 문제
- 캐시와 메모리는 캐시 라인 단위로 상호작용 한다
- 서로 다른 변수를 가진 전역 구조체에 대해, 다중 스레드 프로그램이 해당 전역 구조체를 참조한다고 가정
	- 이때 스레드 A 는 구조체의 a 변수를,
	- 스레드 B는 구조체의 b 변수를 참조한다
- 이때에도 캐시 핑퐁 문제가 발생하는데...
	- 원인은 구조체에 a 와 b 변수가 인접해서 선언되었고, 이 변수들이 동일한 캐시 라인에 있을 가능성이 매우 높아서란다...
	- 그래서 스레드 A 가 a 변수에 접근할 때 캐시 미스가 되면 a 와 b 변수가 포함된 캐시 라인을 저장하게 되고, 동시에 스레드 B 가 b 변수에 접근할 때 캐시 미스가 되면 다시 a 와 b 변수가 포함된 캐시 라인이 저장된다
	- 이렇게 핑퐁치게 되서 느리다는 것
- 이렇게 여러 개의 스레드가 어떠한 데이터도 공유하지 않은 것 처럼 보이지만 캐시 동작 방식에 따라 캐시 라인을 공유하고 있는 것을 거짓 공유라고 한단다
- 그래서 이걸 방지하려면 a 와 b 중간에 64바이트짜리 자료형 하나를 선언하면 된다 ㅋ
	- 이렇게 하면 a 와 b 는 같은 캐시 라인에 포함되지 않을 것이다